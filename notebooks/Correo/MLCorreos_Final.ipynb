{"cells":[{"cell_type":"code","source":["Correos_df = spark.sql(\"select cast(sender as string), bodyPreview, receivedDateTime, hasAttachments, importance, cast(subject as string), case when upper(bodyPreview) like '% UIS %' AND cast(sender as string) like '%uis%' OR cast(subject as string) like '%cursos%' OR upper(bodyPreview) like '%CORDIAL%' OR importance like '%high%' or hasAttachments then 1 else 0 end Fraude from correos700_json \")\nCorreos_df.createOrReplaceTempView(\"correos\")\nCorreos_df.printSchema()\nCorreos_df.show(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- sender: string (nullable = true)\n-- bodyPreview: string (nullable = true)\n-- receivedDateTime: string (nullable = true)\n-- hasAttachments: boolean (nullable = true)\n-- importance: string (nullable = true)\n-- subject: string (nullable = true)\n-- Fraude: integer (nullable = false)\n\n+--------------------+--------------------+--------------------+--------------+----------+--------------------+------+\n              sender|         bodyPreview|    receivedDateTime|hasAttachments|importance|             subject|Fraude|\n+--------------------+--------------------+--------------------+--------------+----------+--------------------+------+\n[[divcult@uis.edu...|ðŸŽ¤ðŸŽ­ðŸ’ƒ - Â¡Agenda ...|2019-05-13T12:43:16Z|         false|    normal|RV: ðŸŽ¤ðŸŽ­ðŸ’ƒ - Â¡Age...|     1|\n[[uisdetodos@uis....|Reclama tu boleta...|2019-05-10T21:24:09Z|         false|    normal|HOY Santiago Bote...|     0|\n[[no-reply@resear...|Juan Pablo, your ...|2019-05-10T14:42:11Z|         false|    normal|Juan Pablo, your ...|     0|\n[[uisdetodos@uis....|#SemanaDeLaBicicl...|2019-05-10T11:59:51Z|         false|    normal|HOY Santiago Bote...|     0|\n[[uisdetodos@uis....|#SemanaDeLaBicicl...|2019-05-09T22:37:31Z|         false|    normal|InvitaciÃ³n Taller...|     0|\n[[uisdetodos@uis....|#SemanaDeLaBicicl...|2019-05-09T20:35:02Z|         false|    normal|HOY Ciclopaseo UI...|     0|\n[[uisdetodos@uis....|#SemanaDeLaBicicl...|2019-05-09T18:31:30Z|         false|    normal|Santiago Botero e...|     0|\n[[relext@uis.edu....|Oficina de Relaci...|2019-05-08T20:16:22Z|         false|      high|F.I. RELEXT - MaÃ±...|     1|\n[[e3t@comunidadui...|Apreciada comunid...|2019-05-08T14:49:45Z|         false|    normal|E3TWeb Especializ...|     1|\n[[uber.colombia@u...|Total: $12,200\r\nW...|2019-05-08T13:45:40Z|         false|    normal|Your Wednesday mo...|     0|\n+--------------------+--------------------+--------------------+--------------+----------+--------------------+------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["Correos_df = spark.sql(\"\"\"select hasAttachments, importance, case when upper(bodyPreview) like '% UIS %' then 1 when upper(bodyPreview) like '% CORDIAL %' then 2 when upper(bodyPreview) like '% CORDIAL %' and upper(bodyPreview) like '% UIS %' then 3 else 0 end Body_UIS, case when sender like '%uis%' then 1 else 0 end Sender_UIS, case when subject like '%cursos%' then 1 when subject like '% uis %' then 2 else 0 end subject_U, Fraude from correos\"\"\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["(train, test) = Correos_df.randomSplit([0.8, 0.2], seed= 12345)\ntrain.cache()\ntest.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">3</span><span class=\"ansired\">]: </span>DataFrame[hasAttachments: boolean, importance: string, Body_UIS: int, Sender_UIS: int, subject_U: int, Fraude: int]\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Reset the DataFrames for no fraud (`dfn`) and fraud (`dfy`)\ndfn = train.filter(train.Fraude == 0)\ndfy = train.filter(train.Fraude == 1)\n\nN = train.count()\ny = dfy.count()\np = y/N\n\ntrain_b = dfn.sample(False, p, seed = 92285).union(dfy)\n\ndisplay(train_b.groupBy(\"Fraude\").count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Fraude</th><th>count</th></tr></thead><tbody><tr><td>1</td><td>107</td></tr><tr><td>0</td><td>79</td></tr></tbody></table></div>"]}}],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import OneHotEncoderEstimator\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import DecisionTreeClassifier\n\nindexer = StringIndexer(inputCol = \"importance\", outputCol = \"importanceIndexed\")\n\n\n\nva = VectorAssembler(inputCols = [\"hasAttachments\",\"importanceIndexed\",\"Body_UIS\",\"Sender_UIS\",\"subject_U\"], outputCol = \"features\")\ndt = DecisionTreeClassifier(labelCol = \"Fraude\", featuresCol = \"features\", seed = 54321, maxDepth = 5,maxBins = 52)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["pipeline_1 = Pipeline(stages=[ indexer, va, dt])\n\nModel_b = pipeline_1.fit(train_b)\ndisplay(Model_b.stages[-1])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>treeNode</th></tr></thead><tbody><tr><td>{\"index\":1,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":0.5,\"categories\":null,\"feature\":3,\"overflow\":false}</td></tr><tr><td>{\"index\":0,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":9,\"featureType\":\"categorical\",\"prediction\":null,\"threshold\":null,\"categories\":[0.0],\"feature\":1,\"overflow\":false}</td></tr><tr><td>{\"index\":7,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":0.5,\"categories\":null,\"feature\":2,\"overflow\":false}</td></tr><tr><td>{\"index\":5,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":0.5,\"categories\":null,\"feature\":0,\"overflow\":false}</td></tr><tr><td>{\"index\":3,\"featureType\":\"continuous\",\"prediction\":null,\"threshold\":0.5,\"categories\":null,\"feature\":4,\"overflow\":false}</td></tr><tr><td>{\"index\":2,\"featureType\":null,\"prediction\":0.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":4,\"featureType\":null,\"prediction\":1.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":6,\"featureType\":null,\"prediction\":1.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":8,\"featureType\":null,\"prediction\":1.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr><tr><td>{\"index\":10,\"featureType\":null,\"prediction\":1.0,\"threshold\":null,\"categories\":null,\"feature\":null,\"overflow\":false}</td></tr></tbody></table></div>"]}}],"execution_count":6},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Use BinaryClassificationEvaluator to evaluate our model\nevaluatorPR = BinaryClassificationEvaluator(labelCol = \"Fraude\", rawPredictionCol = \"prediction\", metricName = \"areaUnderPR\")\nevaluatorAUC = BinaryClassificationEvaluator(labelCol = \"Fraude\", rawPredictionCol = \"prediction\", metricName = \"areaUnderROC\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\n# Build the grid of different parameters\nparamGrid = ParamGridBuilder() \\\n    .addGrid(dt.maxDepth, [5, 10, 15]) \\\n    .addGrid(dt.maxBins, [15, 20, 60]) \\\n    .build()\n\n# Build out the cross validation\ncrossval = CrossValidator(estimator = dt,\n                          estimatorParamMaps = paramGrid,\n                          evaluator = evaluatorPR,\n                          numFolds = 3)  \n\npipelineCV = Pipeline(stages=[indexer, va, crossval])\n\n# Train the model using the pipeline, parameter grid, and preceding BinaryClassificationEvaluator\ncvModel_u = pipelineCV.fit(train_b)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["train_pred = cvModel_u.transform(train_b)\ntest_pred = cvModel_u.transform(test)\npr_train = evaluatorPR.evaluate(train_pred)\nauc_train = evaluatorAUC.evaluate(train_pred)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["# Create confusion matrix template\nfrom pyspark.sql.functions import lit, expr, col, column\n\n# Confusion matrix template\ncmt = spark.createDataFrame([(1, 0), (0, 0), (1, 1), (0, 1)], [\"Fraude\", \"prediction\"])\ncmt.createOrReplaceTempView(\"cmt\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["# Source code for plotting confusion matrix is based on `plot_confusion_matrix` \n# via https://runawayhorse001.github.io/LearningApacheSpark/classification.html#decision-tree-classification\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport itertools\n\ndef plot_confusion_matrix(cm, title):\n  # Clear Plot\n  plt.gcf().clear()\n\n  # Configure figure\n  fig = plt.figure(1)\n  \n  # Configure plot\n  classes = ['Fraud', 'No Fraud']\n  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n  plt.title(title)\n  plt.colorbar()\n  tick_marks = np.arange(len(classes))\n  plt.xticks(tick_marks, classes, rotation=45)\n  plt.yticks(tick_marks, classes)\n\n  # Normalize and establish threshold\n  normalize=False\n  fmt = 'd'\n  thresh = cm.max() / 2.\n\n  # Iterate through the confusion matrix cells\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n      plt.text(j, i, format(cm[i, j], fmt),\n               horizontalalignment=\"center\",\n               color=\"white\" if cm[i, j] > thresh else \"black\")\n\n  # Final plot configurations\n  plt.tight_layout()\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label') \n  \n  # Display images\n  image = fig\n  \n  # Show plot\n  #fig = plt.show()\n  \n  # Save plot\n  fig.savefig(\"confusion-matrix.png\")\n\n  # Display Plot\n  display(image)\n  \n  # Close Plot\n  plt.close(fig)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["# Create temporary view for test predictions\ntest_pred.createOrReplaceTempView(\"test_pred\")\n\nTest_pred_cmdf = spark.sql(\"select a.Fraude, a.prediction, coalesce(b.count, 0) as count from cmt a left outer join (select Fraude, prediction, count(1) as count from test_pred group by Fraude, prediction) b on b.Fraude = a.Fraude and b.prediction = a.prediction order by a.Fraude desc, a.prediction desc\")\n\n# View confusion matrix\ndisplay(Test_pred_cmdf)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Fraude</th><th>prediction</th><th>count</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>30</td></tr><tr><td>1</td><td>0</td><td>2</td></tr><tr><td>0</td><td>1</td><td>0</td></tr><tr><td>0</td><td>0</td><td>118</td></tr></tbody></table></div>"]}}],"execution_count":12},{"cell_type":"code","source":["cm_pdf = Test_pred_cmdf.toPandas()\n\n# Create 1d numpy array of confusion matrix values\ncm_1d = cm_pdf.iloc[:, 2]\n\n# Create 2d numpy array of confusion matrix values\ncm = np.reshape(cm_1d, (-1, 2))\n\n# Print out the 2d array\nprint(cm)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.5/site-packages/numpy/core/fromnumeric.py:225: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n  return reshape(newshape, order=order)\n[[ 30   2]\n [  0 118]]\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["plot_confusion_matrix(cm, \"Confusion Matrix \")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"image/png":["/plots/7645b59d-f205-4fe6-a9d5-7652a9d536a7.png"]}}],"execution_count":14},{"cell_type":"code","source":["train_pred = Model_b.transform(train_b)\ntest_pred = Model_b.transform(test)\npr_train = evaluatorPR.evaluate(train_pred)\nauc_train = evaluatorAUC.evaluate(train_pred)\n\n# Evaluate the model on training datasets\npr_train = evaluatorPR.evaluate(train_pred)\nauc_train = evaluatorAUC.evaluate(train_pred)\n\n# Evaluate the model on test datasets\npr_test = evaluatorPR.evaluate(test_pred)\nauc_test = evaluatorAUC.evaluate(test_pred)\n\n# Print out the PR and AUC values\nprint(\"PR train:\", pr_train)\nprint(\"AUC train:\", auc_train)\nprint(\"PR test:\", pr_test)\nprint(\"AUC test:\", auc_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">PR train: 0.9880916490804944\nAUC train: 0.9719626168224299\nPR test: 0.9754166666666667\nAUC test: 0.96875\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["import mlflow\nimport mlflow.spark\n\nimport os\nmlflow_experiment_id = 1030082808670079\nwith mlflow.start_run(experiment_id = mlflow_experiment_id) as run:\n  # Log Parameters and metrics\n  mlflow.log_param(\"balanced\", \"yes\")\n  mlflow.log_metric(\"PR train\", pr_train)\n  mlflow.log_metric(\"AUC train\", auc_train)\n  mlflow.log_metric(\"PR test\", pr_test)\n  mlflow.log_metric(\"AUC test\", auc_test)\n  \n  # Log model\n  mlflow.spark.log_model(Model_b, \"model\")\n  \n  # Log Confusion matrix\n  mlflow.log_artifact(\"confusion-matrix.png\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":17}],"metadata":{"name":"MLCorreos_Final","notebookId":3366569080918352},"nbformat":4,"nbformat_minor":0}